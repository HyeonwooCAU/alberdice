# AlberDICE coordinate
buffer_size: 5000

# use epsilon greedy action selector
action_selector:  "multinomial"
epsilon_start: 0.0
epsilon_finish: 0.0
epsilon_anneal_time: 50000
mask_before_softmax: True


lr: 0.0001
nu_lr: 0.0001
alpha_start: 5  # balancing term for kl-regularization
alpha_end: 0.001
agent_output_type: "pi_logits"
learner: "alberdice_learner"

num_iter_inner_loop: 1

absorbing_state: True

autoregressive_data_policy: True # use an autoregressive data policy

e_for_w_max: 20
other_policy_ratio_max: 100


#env_args:
#  state_last_action: False
runner: "episode"
name: "alberdice"
